{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import skimage\n",
    "import dlib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import torchvision.transforms.functional as tf\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../train_org_img/ANGRY/angry1.jpg', '../train_org_img/ANGRY/angry10.jpg', '../train_org_img/ANGRY/angry11.jpg', '../train_org_img/ANGRY/angry12.jpg', '../train_org_img/ANGRY/angry13.jpg', '../train_org_img/ANGRY/angry15.jpg', '../train_org_img/ANGRY/angry16.jpg', '../train_org_img/ANGRY/angry17.jpg', '../train_org_img/ANGRY/angry18.jpg', '../train_org_img/ANGRY/angry19.jpg', '../train_org_img/ANGRY/angry2.jpg', '../train_org_img/ANGRY/angry20.jpg', '../train_org_img/ANGRY/angry21.jpg', '../train_org_img/ANGRY/angry23.jpg', '../train_org_img/ANGRY/angry24.jpg', '../train_org_img/ANGRY/angry25.jpg', '../train_org_img/ANGRY/angry26.jpg', '../train_org_img/ANGRY/angry27.jpg', '../train_org_img/ANGRY/angry28.jpg', '../train_org_img/ANGRY/angry29.jpg', '../train_org_img/ANGRY/angry3.jpg', '../train_org_img/ANGRY/angry30.jpg', '../train_org_img/ANGRY/angry4.jpg', '../train_org_img/ANGRY/angry5.jpg', '../train_org_img/ANGRY/angry6.jpg', '../train_org_img/ANGRY/angry7.jpg', '../train_org_img/ANGRY/angry8.jpg', '../train_org_img/ANGRY/angry9.jpg', '../train_org_img/DISGUST/disgust1.jpg', '../train_org_img/DISGUST/disgust10.jpg', '../train_org_img/DISGUST/disgust11.jpg', '../train_org_img/DISGUST/disgust12.jpg', '../train_org_img/DISGUST/disgust13.jpg', '../train_org_img/DISGUST/disgust14.jpg', '../train_org_img/DISGUST/disgust15.jpg', '../train_org_img/DISGUST/disgust17.jpg', '../train_org_img/DISGUST/disgust18.jpg', '../train_org_img/DISGUST/disgust19.jpg', '../train_org_img/DISGUST/disgust20.jpg', '../train_org_img/DISGUST/disgust21.jpg', '../train_org_img/DISGUST/disgust22.jpg', '../train_org_img/DISGUST/disgust23.jpg', '../train_org_img/DISGUST/disgust24.jpg', '../train_org_img/DISGUST/disgust25.jpg', '../train_org_img/DISGUST/disgust26.jpg', '../train_org_img/DISGUST/disgust27.jpg', '../train_org_img/DISGUST/disgust28.jpg', '../train_org_img/DISGUST/disgust29.jpg', '../train_org_img/DISGUST/disgust3.jpg', '../train_org_img/DISGUST/disgust4.jpg', '../train_org_img/DISGUST/disgust5.jpg', '../train_org_img/DISGUST/disgust6.jpg', '../train_org_img/DISGUST/disgust7.jpg', '../train_org_img/DISGUST/disgust8.jpg', '../train_org_img/DISGUST/disgust9.jpg', '../train_org_img/FEAR/fear1.jpg', '../train_org_img/FEAR/fear10.jpg', '../train_org_img/FEAR/fear11.jpg', '../train_org_img/FEAR/fear13.jpg', '../train_org_img/FEAR/fear14.jpg', '../train_org_img/FEAR/fear15.jpg', '../train_org_img/FEAR/fear16.jpg', '../train_org_img/FEAR/fear17.jpg', '../train_org_img/FEAR/fear18.jpg', '../train_org_img/FEAR/fear19.jpg', '../train_org_img/FEAR/fear20.jpg', '../train_org_img/FEAR/fear21.jpg', '../train_org_img/FEAR/fear22.jpg', '../train_org_img/FEAR/fear23.jpg', '../train_org_img/FEAR/fear24.jpg', '../train_org_img/FEAR/fear25.jpg', '../train_org_img/FEAR/fear26.jpg', '../train_org_img/FEAR/fear27.jpg', '../train_org_img/FEAR/fear28.jpg', '../train_org_img/FEAR/fear29.jpg', '../train_org_img/FEAR/fear3.jpg', '../train_org_img/FEAR/fear30.jpg', '../train_org_img/FEAR/fear31.jpg', '../train_org_img/FEAR/fear32.jpg', '../train_org_img/FEAR/fear4.jpg', '../train_org_img/FEAR/fear5.jpg', '../train_org_img/FEAR/fear6.jpg', '../train_org_img/FEAR/fear7.jpg', '../train_org_img/FEAR/fear8.jpg', '../train_org_img/FEAR/fear9.jpg', '../train_org_img/HAPPY/happy1.jpg', '../train_org_img/HAPPY/happy10.jpg', '../train_org_img/HAPPY/happy11.jpg', '../train_org_img/HAPPY/happy12.jpg', '../train_org_img/HAPPY/happy13.jpg', '../train_org_img/HAPPY/happy14.jpg', '../train_org_img/HAPPY/happy15.jpg', '../train_org_img/HAPPY/happy16.jpg', '../train_org_img/HAPPY/happy17.jpg', '../train_org_img/HAPPY/happy18.jpg', '../train_org_img/HAPPY/happy2.jpg', '../train_org_img/HAPPY/happy20.jpg', '../train_org_img/HAPPY/happy21.jpg', '../train_org_img/HAPPY/happy22.jpg', '../train_org_img/HAPPY/happy23.jpg', '../train_org_img/HAPPY/happy24.jpg', '../train_org_img/HAPPY/happy25.jpg', '../train_org_img/HAPPY/happy26.jpg', '../train_org_img/HAPPY/happy27.jpg', '../train_org_img/HAPPY/happy29.jpg', '../train_org_img/HAPPY/happy3.jpg', '../train_org_img/HAPPY/happy30.jpg', '../train_org_img/HAPPY/happy31.jpg', '../train_org_img/HAPPY/happy4.jpg', '../train_org_img/HAPPY/happy5.jpg', '../train_org_img/HAPPY/happy6.jpg', '../train_org_img/HAPPY/happy7.jpg', '../train_org_img/HAPPY/happy8.jpg', '../train_org_img/HAPPY/happy9.jpg', '../train_org_img/NEUTRAL/neutral1.jpg', '../train_org_img/NEUTRAL/neutral10.jpg', '../train_org_img/NEUTRAL/neutral12.jpg', '../train_org_img/NEUTRAL/neutral13.jpg', '../train_org_img/NEUTRAL/neutral14.jpg', '../train_org_img/NEUTRAL/neutral15.jpg', '../train_org_img/NEUTRAL/neutral16.jpg', '../train_org_img/NEUTRAL/neutral17.jpg', '../train_org_img/NEUTRAL/neutral18.jpg', '../train_org_img/NEUTRAL/neutral19.jpg', '../train_org_img/NEUTRAL/neutral2.jpg', '../train_org_img/NEUTRAL/neutral20.jpg', '../train_org_img/NEUTRAL/neutral22.jpg', '../train_org_img/NEUTRAL/neutral23.jpg', '../train_org_img/NEUTRAL/neutral24.jpg', '../train_org_img/NEUTRAL/neutral25.jpg', '../train_org_img/NEUTRAL/neutral26.jpg', '../train_org_img/NEUTRAL/neutral27.jpg', '../train_org_img/NEUTRAL/neutral28.jpg', '../train_org_img/NEUTRAL/neutral29.jpg', '../train_org_img/NEUTRAL/neutral3.jpg', '../train_org_img/NEUTRAL/neutral30.jpg', '../train_org_img/NEUTRAL/neutral4.jpg', '../train_org_img/NEUTRAL/neutral5.jpg', '../train_org_img/NEUTRAL/neutral6.jpg', '../train_org_img/NEUTRAL/neutral7.jpg', '../train_org_img/NEUTRAL/neutral8.jpg', '../train_org_img/NEUTRAL/neutral9.jpg', '../train_org_img/SAD/sad1.jpg', '../train_org_img/SAD/sad10.jpg', '../train_org_img/SAD/sad11.jpg', '../train_org_img/SAD/sad12.jpg', '../train_org_img/SAD/sad13.jpg', '../train_org_img/SAD/sad14.jpg', '../train_org_img/SAD/sad15.jpg', '../train_org_img/SAD/sad16.jpg', '../train_org_img/SAD/sad17.jpg', '../train_org_img/SAD/sad18.jpg', '../train_org_img/SAD/sad19.jpg', '../train_org_img/SAD/sad2.jpg', '../train_org_img/SAD/sad20.jpg', '../train_org_img/SAD/sad21.jpg', '../train_org_img/SAD/sad23.jpg', '../train_org_img/SAD/sad24.jpg', '../train_org_img/SAD/sad25.jpg', '../train_org_img/SAD/sad26.jpg', '../train_org_img/SAD/sad27.jpg', '../train_org_img/SAD/sad28.jpg', '../train_org_img/SAD/sad29.jpg', '../train_org_img/SAD/sad3.jpg', '../train_org_img/SAD/sad30.jpg', '../train_org_img/SAD/sad31.jpg', '../train_org_img/SAD/sad4.jpg', '../train_org_img/SAD/sad5.jpg', '../train_org_img/SAD/sad6.jpg', '../train_org_img/SAD/sad8.jpg', '../train_org_img/SAD/sad9.jpg', '../train_org_img/SURPRISE/surprise1.jpg', '../train_org_img/SURPRISE/surprise10.jpg', '../train_org_img/SURPRISE/surprise11.jpg', '../train_org_img/SURPRISE/surprise12.jpg', '../train_org_img/SURPRISE/surprise13.jpg', '../train_org_img/SURPRISE/surprise14.jpg', '../train_org_img/SURPRISE/surprise15.jpg', '../train_org_img/SURPRISE/surprise16.jpg', '../train_org_img/SURPRISE/surprise17.jpg', '../train_org_img/SURPRISE/surprise18.jpg', '../train_org_img/SURPRISE/surprise19.jpg', '../train_org_img/SURPRISE/surprise2.jpg', '../train_org_img/SURPRISE/surprise20.jpg', '../train_org_img/SURPRISE/surprise22.jpg', '../train_org_img/SURPRISE/surprise23.jpg', '../train_org_img/SURPRISE/surprise24.jpg', '../train_org_img/SURPRISE/surprise25.jpg', '../train_org_img/SURPRISE/surprise26.jpg', '../train_org_img/SURPRISE/surprise27.jpg', '../train_org_img/SURPRISE/surprise28.jpg', '../train_org_img/SURPRISE/surprise3.jpg', '../train_org_img/SURPRISE/surprise30.jpg', '../train_org_img/SURPRISE/surprise4.jpg', '../train_org_img/SURPRISE/surprise5.jpg', '../train_org_img/SURPRISE/surprise6.jpg', '../train_org_img/SURPRISE/surprise7.jpg', '../train_org_img/SURPRISE/surprise8.jpg', '../train_org_img/SURPRISE/surprise9.jpg']\n"
     ]
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# file_name_list = glob.glob('../train_org_img/*/*')\n",
    "file_name_list = glob.glob('../train_org_img/SURPRISE/*')\n",
    "print(file_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bgimg:\n",
    "bg_list = glob.glob('bgimg/*')\n",
    "\n",
    "def rand_load_bgimg():\n",
    "    bg_idx = random.randint(0,4)\n",
    "#     bg_list.length()\n",
    "    bg_path = bg_list[bg_idx]\n",
    "#     bg_img = dlib.load_rgb_image(bg_path)\n",
    "    bg_img = Image.open(bg_path)\n",
    "#     plt.imshow(bg_img)\n",
    "    area = (0, 0, 256, 256)\n",
    "    bg_img = bg_img.crop(area)\n",
    "    bg_img = tf.to_grayscale(bg_img, num_output_channels=3)\n",
    "    return bg_img\n",
    "\n",
    "# rand_load_bgimg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transFace(face_with_mask):\n",
    "#     eval_transformer = torchvision.transforms.Compose([\n",
    "#     torchvision.transforms.RandomAffine((-180, 180), translate=(0.5,0.5), scale=(0.5,1.5))\n",
    "#     torchvision.transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.485, 0.456, 0.406),\n",
    "#                          (0.229, 0.224, 0.225)),\n",
    "#     ])  # transform it into a torch tensor\n",
    "\n",
    "    pil_with_mask = Image.fromarray(face_with_mask)\n",
    "    angle = random.randint(-180, 180)\n",
    "    scale = random.uniform(0.3,1.5)\n",
    "    translateH = random.randint(-20, 20)\n",
    "    translateV = random.randint(-20, 20)\n",
    "\n",
    "    trans_img = tf.affine(img = pil_with_mask, angle = angle, translate = (translateH, translateV), scale = scale, shear = 0)\n",
    "\n",
    "#     torchvision.transforms.RandomAffine(degrees, translate=None, scale=None, shear=None, resample=False, fillcolor=0)\n",
    "    return trans_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendFace(trans_pil):\n",
    "    bg_img_pil = rand_load_bgimg()\n",
    "    trans_np = np.array(trans_pil)\n",
    "    bg_img_np = np.array(bg_img_pil)\n",
    "    bg_img_np = np.reshape(bg_img_np,(256,256,3))\n",
    "    face_mask = trans_np[:,:,2]\n",
    "    face_mask_3_dim = np.reshape(face_mask,(256,256,1))\n",
    "    bg_img_np_mask = bg_img_np * (1-face_mask_3_dim)\n",
    "    appended_img = bg_img_np_mask + trans_np\n",
    "#     bg_img_pil.paste(trans_pil)\n",
    "#     bg_img_pil.show()\n",
    "    return appended_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def getMaskedImage(file_path):\n",
    "    img = dlib.load_rgb_image(file_path)\n",
    "#     print(file_path)\n",
    "\n",
    "    emotion_tag = file_path.split(\"/\")[2]\n",
    "    filename = file_path.split(\"/\")[3].split(\".\")[0]\n",
    "    \n",
    "    rect = detector(img)[0]\n",
    "    sp = predictor(img, rect)\n",
    "    landmarks = np.array([[p.x, p.y] for p in sp.parts()])\n",
    "    outline = landmarks[[*range(17), *range(26,16,-1)]]\n",
    "    Y, X = skimage.draw.polygon(outline[:,1], outline[:,0])\n",
    "    np.clip(X, 0, 255, out = X)\n",
    "    np.clip(Y, 0, 255, out = Y)\n",
    "#     clip for out range\n",
    "    cropped_img = np.zeros(img.shape, dtype=np.uint8)\n",
    "    cropped_img[Y, X] = img[Y, X]\n",
    "    \n",
    "    img_mask = np.zeros(img.shape,dtype=np.uint8)\n",
    "    img_mask[Y,X] = 1\n",
    "#     call trans\n",
    "# SAVE TRANS IMG\n",
    "    # TODO?: save mask as [:,:,3] here?\n",
    "    cropped_img[:,:,2] = img_mask[:,:,2]\n",
    "    \n",
    "    counter = 0\n",
    "    for counter in range(5):\n",
    "        trans_img_pil = transFace(cropped_img)\n",
    "    #     Image.fromarray(trans_img).save(outimg_path)\n",
    "        pil_comb_np = appendFace(trans_img_pil)\n",
    "        pil_comb_pil = Image.fromarray(pil_comb_np)\n",
    "        br_ct = 0\n",
    "        \n",
    "        for br_ct in range(4):\n",
    "            brightness_factor = random.uniform(0,2)\n",
    "            result_img = tf.adjust_brightness(pil_comb_pil, brightness_factor)\n",
    "    #         Image.fromarray(pil_comb).save(outimg_path)\n",
    "            outimg_path = os.path.join(\"outimg\", emotion_tag, filename + \"_f\" + str(counter) + \"_br\" + str(br_ct)+ \".jpg\" )\n",
    "            result_img.save(outimg_path)\n",
    "            br_ct +=1\n",
    "            \n",
    "        counter += 1\n",
    "#     trans_img.save(pil_img)\n",
    "#     plt.imshow(img_mask[:,:,2])\n",
    "#     img_mask.shape\n",
    "#     return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-02849abb28b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_name_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgetMaskedImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#     print (file_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     croppedImg = getMaskedImage(filePath)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c8d65357def4>\u001b[0m in \u001b[0;36mgetMaskedImage\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtrans_img_pil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#     Image.fromarray(trans_img).save(outimg_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mpil_comb_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappendFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_img_pil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mpil_comb_pil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpil_comb_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mbr_ct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-83e3e9aa9039>\u001b[0m in \u001b[0;36mappendFace\u001b[0;34m(trans_pil)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mappendFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_pil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbg_img_pil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_load_bgimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrans_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_pil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbg_img_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg_img_pil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbg_img_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg_img_np\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f66295a676a9>\u001b[0m in \u001b[0;36mrand_load_bgimg\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbg_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     bg_list.length()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbg_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#     bg_img = dlib.load_rgb_image(bg_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbg_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for file_path in file_name_list:\n",
    "    getMaskedImage(file_path)\n",
    "#     print (file_path)\n",
    "#     croppedImg = getMaskedImage(filePath)\n",
    "# plt.imshow(croppedImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ecfa281ab2da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "Image.fromarray(np.zeros(3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-838fb92d9e93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "Image.fromarray(np.zeros(100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
